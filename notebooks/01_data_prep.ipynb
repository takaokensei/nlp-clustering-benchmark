{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 01 - Prepara√ß√£o de Dados\n",
        "\n",
        "Este notebook carrega e prepara as bases de dados PT-6 e 20NG-6.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Adicionar src ao path\n",
        "project_root = Path().resolve().parent\n",
        "sys.path.append(str(project_root))\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from src.config import RAW_DATA_DIR, TWENTY_NG_CATEGORIES, PT6_CLASS_COLUMN_CANDIDATES\n",
        "from src.utils import detect_class_column\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Carregar 20NG-6 (20 Newsgroups - 6 categorias)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total de documentos: 5906\n",
            "N√∫mero de classes: 6\n",
            "Classes: ['comp.graphics', 'comp.sys.mac.hardware', 'rec.autos', 'rec.sport.hockey', 'sci.crypt', 'sci.med']\n",
            "\n",
            "Distribui√ß√£o de classes:\n",
            "class_name\n",
            "rec.sport.hockey         999\n",
            "sci.crypt                991\n",
            "rec.autos                990\n",
            "sci.med                  990\n",
            "comp.graphics            973\n",
            "comp.sys.mac.hardware    963\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Carregar 20 Newsgroups com 6 categorias selecionadas\n",
        "newsgroups = fetch_20newsgroups(\n",
        "    subset='all',\n",
        "    categories=TWENTY_NG_CATEGORIES,\n",
        "    remove=('headers', 'footers', 'quotes'),\n",
        "    shuffle=True,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(f\"Total de documentos: {len(newsgroups.data)}\")\n",
        "print(f\"N√∫mero de classes: {len(newsgroups.target_names)}\")\n",
        "print(f\"Classes: {newsgroups.target_names}\")\n",
        "\n",
        "# Criar DataFrame\n",
        "df_20ng = pd.DataFrame({\n",
        "    'text': newsgroups.data,\n",
        "    'class': newsgroups.target,\n",
        "    'class_name': [newsgroups.target_names[i] for i in newsgroups.target]\n",
        "})\n",
        "\n",
        "print(f\"\\nDistribui√ß√£o de classes:\")\n",
        "print(df_20ng['class_name'].value_counts())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Carregar PT-6 (CSV)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üì• Carregando C:\\nlp-clustering-benchmark\\data\\raw\\pt6.csv...\n",
            "   Total inicial: 319 documentos\n",
            "   Coluna de classe detectada: Categoria\n",
            "   Coluna de texto detectada: Texto Expandido\n",
            "\\nüßπ Pr√©-processando dados...\n",
            "‚ö†Ô∏è Removidos 4 documentos inv√°lidos\n",
            "   ‚úÖ CSV pr√©-processado salvo em: C:\\nlp-clustering-benchmark\\data\\raw\\pt6_preprocessed.csv\n",
            "\\nüìä Total ap√≥s limpeza: 315 documentos\n",
            "\\nDistribui√ß√£o de classes:\n",
            "Categoria\n",
            "Turismo                   58\n",
            "Pol√≠cia e Direitos        55\n",
            "Esportes                  53\n",
            "Economia                  53\n",
            "Pol√≠tica                  51\n",
            "Variedades e Sociedade    45\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Carregar e pr√©-processar PT-6\n",
        "pt6_file = RAW_DATA_DIR / \"pt6.csv\"\n",
        "pt6_preprocessed_file = RAW_DATA_DIR / \"pt6_preprocessed.csv\"\n",
        "\n",
        "# Fun√ß√£o para limpar textos (remover NaN e valores vazios)\n",
        "def clean_texts(df, text_column):\n",
        "    \"\"\"Remove linhas com NaN ou valores vazios na coluna de texto.\"\"\"\n",
        "    original_len = len(df)\n",
        "    \n",
        "    # Criar c√≥pia para n√£o modificar o original\n",
        "    df_clean = df.copy()\n",
        "    \n",
        "    # Converter para string e tratar NaN explicitamente\n",
        "    df_clean[text_column] = df_clean[text_column].astype(str)\n",
        "    \n",
        "    # Remover linhas onde o texto √© 'nan' (string), 'None', ou vazio\n",
        "    mask = (\n",
        "        (df_clean[text_column] != 'nan') &\n",
        "        (df_clean[text_column] != 'None') &\n",
        "        (df_clean[text_column].str.strip() != '') &\n",
        "        (df_clean[text_column].notna())\n",
        "    )\n",
        "    df_clean = df_clean[mask].copy()\n",
        "    \n",
        "    # Garantir que s√£o strings v√°lidas e remover espa√ßos extras\n",
        "    df_clean[text_column] = df_clean[text_column].str.strip()\n",
        "    \n",
        "    # Remover qualquer linha que ainda tenha NaN (verifica√ß√£o final)\n",
        "    df_clean = df_clean[df_clean[text_column].notna()].copy()\n",
        "    \n",
        "    cleaned_len = len(df_clean)\n",
        "    \n",
        "    if original_len != cleaned_len:\n",
        "        print(f\"‚ö†Ô∏è Removidos {original_len - cleaned_len} documentos inv√°lidos\")\n",
        "    \n",
        "    # Resetar √≠ndice\n",
        "    df_clean = df_clean.reset_index(drop=True)\n",
        "    \n",
        "    # Verifica√ß√£o final: garantir que n√£o h√° NaN\n",
        "    nan_count = df_clean[text_column].isna().sum()\n",
        "    if nan_count > 0:\n",
        "        print(f\"‚ö†Ô∏è ATEN√á√ÉO: Ainda h√° {nan_count} valores NaN ap√≥s limpeza!\")\n",
        "        df_clean = df_clean[df_clean[text_column].notna()].reset_index(drop=True)\n",
        "    \n",
        "    return df_clean\n",
        "\n",
        "if pt6_file.exists():\n",
        "    print(f\"üì• Carregando {pt6_file}...\")\n",
        "    df_pt6 = pd.read_csv(pt6_file, encoding='utf-8')\n",
        "    print(f\"   Total inicial: {len(df_pt6)} documentos\")\n",
        "    \n",
        "    # Detectar coluna de classe dinamicamente\n",
        "    class_col = detect_class_column(df_pt6, PT6_CLASS_COLUMN_CANDIDATES)\n",
        "    \n",
        "    if class_col:\n",
        "        print(f\"   Coluna de classe detectada: {class_col}\")\n",
        "        \n",
        "        # Detectar coluna de texto (priorizar 'Texto Expandido')\n",
        "        text_col = 'Texto Expandido' if 'Texto Expandido' in df_pt6.columns else 'Texto Original'\n",
        "        print(f\"   Coluna de texto detectada: {text_col}\")\n",
        "        \n",
        "        # Limpar dados\n",
        "        print(f\"\\\\nüßπ Pr√©-processando dados...\")\n",
        "        df_pt6 = clean_texts(df_pt6, text_col)\n",
        "        \n",
        "        # Salvar CSV pr√©-processado\n",
        "        df_pt6.to_csv(pt6_preprocessed_file, index=False, encoding='utf-8-sig')\n",
        "        print(f\"   ‚úÖ CSV pr√©-processado salvo em: {pt6_preprocessed_file}\")\n",
        "        \n",
        "        print(f\"\\\\nüìä Total ap√≥s limpeza: {len(df_pt6)} documentos\")\n",
        "        print(f\"\\\\nDistribui√ß√£o de classes:\")\n",
        "        print(df_pt6[class_col].value_counts())\n",
        "    else:\n",
        "        print(\"ERRO: N√£o foi poss√≠vel detectar a coluna de classe!\")\n",
        "        print(f\"Colunas dispon√≠veis: {df_pt6.columns.tolist()}\")\n",
        "else:\n",
        "    print(f\"Arquivo n√£o encontrado: {pt6_file}\")\n",
        "    print(\"Por favor, adicione o arquivo CSV do PT-6 em data/raw/\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Carregar Dados Pr√©-processados (Opcional)\n",
        "\n",
        "Se voc√™ j√° executou a c√©lula anterior, pode carregar diretamente o CSV pr√©-processado.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\\n============================================================\n",
            "RESUMO DOS DADOS\n",
            "============================================================\n",
            "\\nüìä 20NG-6: 5906 documentos, 6 classes\n",
            "üìä PT-6: 315 documentos, 6 classes\n",
            "\\n‚úÖ Dados prontos para gera√ß√£o de embeddings!\n"
          ]
        }
      ],
      "source": [
        "# Carregar dados pr√©-processados se necess√°rio\n",
        "if 'df_pt6' not in locals() or df_pt6 is None:\n",
        "    pt6_preprocessed_file = RAW_DATA_DIR / \"pt6_preprocessed.csv\"\n",
        "    if pt6_preprocessed_file.exists():\n",
        "        print(\"üì• Carregando PT-6 pr√©-processado...\")\n",
        "        df_pt6 = pd.read_csv(pt6_preprocessed_file, encoding='utf-8-sig')\n",
        "        class_col = detect_class_column(df_pt6, PT6_CLASS_COLUMN_CANDIDATES)\n",
        "        print(f\"   ‚úÖ {len(df_pt6)} documentos carregados\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è Arquivo pr√©-processado n√£o encontrado. Execute a c√©lula anterior primeiro.\")\n",
        "\n",
        "print(\"\\\\n\" + \"=\" * 60)\n",
        "print(\"RESUMO DOS DADOS\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\\\nüìä 20NG-6: {len(df_20ng)} documentos, {df_20ng['class'].nunique()} classes\")\n",
        "if 'df_pt6' in locals() and 'class_col' in locals() and class_col:\n",
        "    print(f\"üìä PT-6: {len(df_pt6)} documentos, {df_pt6[class_col].nunique()} classes\")\n",
        "    print(\"\\\\n‚úÖ Dados prontos para gera√ß√£o de embeddings!\")\n",
        "else:\n",
        "    print(\"\\\\n‚ùå PT-6 n√£o est√° dispon√≠vel. Execute a c√©lula anterior primeiro.\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
